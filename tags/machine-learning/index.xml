<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Amitrajit Bose</title>
    <link>https://amitrajitbose.github.io/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Amitrajit Bose</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Wed, 16 Oct 2019 09:34:24 +0530</lastBuildDate>
    
	<atom:link href="https://amitrajitbose.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Handling Imbalanced Datasets Using SMOTE</title>
      <link>https://amitrajitbose.github.io/blog/smote/</link>
      <pubDate>Wed, 16 Oct 2019 09:34:24 +0530</pubDate>
      
      <guid>https://amitrajitbose.github.io/blog/smote/</guid>
      <description>Introduction Close your eyes. Now imagine a perfect data world. What do you see? What do you wish to see? Exactly, me too. A flawlessly balanced dataset. A collection of data whose labels form a magnificent 1:1 ratio: 50% of this, 50% of that; not a bit to the left, nor a bit to the right. Just perfectly balanced, as all things should be. Now open your eyes, and come back to the real world.</description>
    </item>
    
    <item>
      <title>Tensorflow Vs PyTorch</title>
      <link>https://amitrajitbose.github.io/blog/tensorflow_vs_pytorch/</link>
      <pubDate>Thu, 05 Sep 2019 03:23:10 +0530</pubDate>
      
      <guid>https://amitrajitbose.github.io/blog/tensorflow_vs_pytorch/</guid>
      <description>Now that you have done quite a lot of machine learning and got those fundamentals solid, it is high time to start with neural networks and deep learning. Although you would not need it in most of the problem statements, it is like a superpower, you have complete control of how you want your network to be, how strong, how big, how weak, how cunning. Actually all you need is access to good data and lots of it.</description>
    </item>
    
    <item>
      <title>Intro to Neural Nets With Pytorch</title>
      <link>https://amitrajitbose.github.io/blog/intro-to-nn-pytorch/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://amitrajitbose.github.io/blog/intro-to-nn-pytorch/</guid>
      <description>Intro To Neural Networks with PyTorch Deep learning networks tend to be massive with dozens or hundreds of layers, that&amp;rsquo;s where the term &amp;ldquo;deep&amp;rdquo; comes from. PyTorch has a nice module nn that provides a nice way to efficiently build large neural networks. Let us together explore it in this blog.
# Import necessary packages %matplotlib inline %config InlineBackend.figure_format = &#39;retina&#39; import numpy as np import torch import helper import matplotlib.</description>
    </item>
    
    <item>
      <title>Hiding Input Cells On Jupyter Notebook</title>
      <link>https://amitrajitbose.github.io/blog/hiding-input-cells-jupyter-notebook/</link>
      <pubDate>Wed, 26 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://amitrajitbose.github.io/blog/hiding-input-cells-jupyter-notebook/</guid>
      <description>Why Needed ? Sometimes we don&amp;rsquo;t want to show the code during presentation of the notebook, or sometimes the code can look really clumsy. Taking care of the code while tearing your hairs to find a better solution to a problem simultaneously is quite a mammoth task. Most tutorials on the web would suggest you to install nbextensions, an open-source notebook extension package for Jupyter notebooks. Definitely that is clean and easy, but I just don&amp;rsquo;t like installing things and junking up my workstation, rather I&amp;rsquo;d write a custom code to solve the problem.</description>
    </item>
    
  </channel>
</rss>